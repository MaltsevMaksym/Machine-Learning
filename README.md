# Машинне навчання
>Тут я буду вносити свій прогрес проходження курсу [Prometheus Course "Machine Learning"](https://apps.prometheus.org.ua/learning/course/course-v1:IRF+ML101+2016_T3/home) за два тижні. 

## Зміст
- [Тиждень 1](#тиждень-1)
  - [День 1](#день-1)
  - [День 2](#день-2)
  - [День 3](#день-3)
  - [День 4](#день-4)
  - [День 5](#день-5)
- [Тиждень 2](#тиждень-2)
  - [День 6](#день-6)
  - [День 7](#день-7)
  - [День 8](#день-8)
  - [День 9](#день-9)
  - [День 10](#день-10)
- [Висновок](#висновок)


## Тиждень 1
> Мета: Дізнатися про основи машинного навчання та нейронні мережі.

> Далі буду надавати конспекти про отримані знання.
### День 1
#### Етапи розробки моделі машинного навчання: представлення даних, конструювання, тестування. Перенавчання. Тренувальна та тестувальна вибірки на прикладі нейронної мережі.

___Машинне навчання___ - це підрозділ штучного інтелекту, який використовує алгоритми для навчання комп'ютерів на основі даних. Воно поділяється на два типи навчання: індуктивне та дедуктивне.

___Індуктивне навчання___ полягає у спостереженні за світом та побудові моделей, які пояснюють причини явищ. Моделі перевіряються і використовуються, покращуються, а деякі можуть бути відкинуті.

___Дедуктивне навчання___ подібне до математики в школі, коли учню дають готові формули та розповідають, як їх застосовувати на практиці.

___Машинне навчання включає три типи___: навчання з вчителем, навчання без вчителя та навчання з підкріпленням.

___Навчання з вчителем___: Використовується набір прикладів, до яких є відомі правильні відповіді. Завдання системи - навчитися надавати правильні відповіді на основі наданих прикладів.

___Навчання без вчителя___: Використовується великий набір даних, в яких система шукає приховані закономірності, такі як кластери або групи.

___Навчання з підкріпленням___: Включає в себе агента, який взаємодіє з певним середовищем і отримує позитивні або негативні відклики за свої дії. Метою є максимізація позитивних відкликів і мінімізація негативних.

__Тестування__ допомагає оцінити якість моделі на незалежних від тренувальної вибірці даних. Якщо модель показує задовільні результати на тестових даних, ми можемо вважати її готовою до застосування на практиці.

Однак, перед тим як перейти до практичного застосування моделі, важливо знати, що процес розробки моделі машинного навчання є ітеративним. Можливо, результати тестування не задовольнять наші вимоги, і тоді потрібно буде повернутись до попередніх етапів, переглянути представлення даних, змінити алгоритм або параметри моделі, і повторити процес тренування та тестування.

Узагалі, процес розробки моделі машинного навчання може виглядати наступним чином:

* Підготовка (представлення) даних:
  * Вибір та підготовка даних для використання в моделі.
  * Ознакове описання об'єктів і вибір ключових ознак.
  * Перетворення даних у формат, зрозумілий для моделі.
  * Конструювання алгоритму:
  * Вибір типу задачі, такий як класифікація, регресія, кластеризація тощо.
  * Вибір підходящого алгоритму для вирішення обраної задачі.
* Тренування алгоритму:
  * Розділення даних на тренувальну та тестову вибірки.
  * Підготовка тренувальної вибірки та навчання моделі на цих даних.
  * Оптимізація параметрів моделі та алгоритму для досягнення кращої продуктивності.
* Валідація алгоритму:
  * Тестування моделі на тестовій вибірці для оцінки її продуктивності.
  * Аналіз результатів та оцінка точності, ефективності та стійкості моделі.
  * Якщо модель показує задовільні результати на тестових даних, можна перейти до практичного застосування моделі для прогнозування, класифікації або вирішення іншої прикладної задачі.

Важливо пам'ятати, що розробка моделі машинного навчання є ітеративним процесом, і може знадобитись декілька циклів для досягнення оптимальних результатів.

### День 2
#### Типи ознак (бінарні, номінальні, порядкові, кількісні). Функціонал якості, квадратична та абсолютна помилки. Лінійна регресія.
Типи ознак: бінарні, номінальні, порядкові, кількісні.

Система машинного навчання вчиться на прикладах для генералізації закономірностей між вхідними та вихідними даними. Вибір і опис ознак впливає на якість результатів.

Є декілька способів опису ознак. Бінарні ознаки використовуються для відповідей "так" або "ні" і описуються бінарним вектором. Номінальні ознаки, які приймають значення від нуля до плюс нескінченності, описуються координатами точки. Порядкові ознаки вказують на позицію в списку або ранжуванні. Кількісні ознаки вимірюють кількість або фізичні характеристики.

Нейронні мережі отримують вектор ознак на вході та надають вектор відповідей на виході. Їх завдання - деформувати простір ознак так, щоб приклади наближалися до очікуваних зон у вихідному просторі.

Розмірність простору ознак зазвичай відрізняється від розмірності простору відповідей. Наприклад, простір відповідей може бути одно- або двовимірним.

Крім опису об'єктів, описуються також відповіді або мітки, які можуть бути бінарними або вказувати на класи, до яких належить об'єкт.

Задачі класифікації можуть бути розділені на неперетинаючі класи (наприклад, "котики чи собачки") або на набір перетинаючихся класів (наприклад, класифікація об'єктів на зображенні).

У задачах регресії міткою може бути будь-який номінальний вектор, який проектує точку на виході на іншу точку.

Під час навчання вибір правильного функціоналу якості має велике значення. Функціонал якості вказує на рівень помилки системи, який намагаємося мінімізувати. Використання різних функціоналів впливає на процес навчання. Наприклад, в задачі регресії можна використовувати функцію квадратичної помилки або абсолютну помилку.

__Лінійна регресія___ - популярний метод в машинному навчанні, який також використовується в економіці. Вона дозволяє вирішувати різноманітні задачі. Припустимо, ми маємо набір спостережень у вигляді двовимірних точок з координатами (X, Y), які мають певну закономірність і зростають у напрямку "плюс нескінченність". Ми хочемо знайти лінію, яка найкращим чином відповідає цим точкам.

Лінійна регресія спробує знайти пряму, яка мінімально віддалена від кожної точки у тренувальному наборі. Ця пряма описується рівнянням y = kx + b, де k - кут нахилу, а b - зміщення прямої. Щоб знайти цю пряму, нам потрібно знайти коефіцієнти k і b, які мінімізують відстань від кожної точки до прямої.
### День 3
####  Мінімізація помилки. Приклад нейронних мереж. Зміна сили зв’язків. Градієнтний спуск.  Логістична регресія. Навчання логістичної регресії. Софт-макс регресія.
У машинному навчанні процес мінімізації помилки грає важливу роль. Це особливо відноситься до нейронних мереж, як одного з прикладів машинного навчання. У нейронних мережах мінімізація помилки досягається шляхом зміни сил зв'язків між нейронами.

Під час навчання нейронної мережі, початкові сили зв'язків зазвичай встановлюються випадково. Потім на виході отримується помилка за допомогою функції втрат, яка оцінює різницю між отриманими та очікуваними результатами. Далі використовується метод градієнтного спуску, щоб змінити сили зв'язків таким чином, щоб наступна ітерація мала меншу помилку.

Градієнтний спуск використовує карту відстаней до точок на площині, де кожна комбінація сил зв'язків представляє потенційну пряму. Метою є знайти точку, яка відповідає найменшій відстані на цій карті, тобто глобальний мінімум. Головне завдання градієнтного спуску - швидко спуститися зі стартової точки до найглибшого мінімуму, уникнувши локальних мінімумів.

Уникнення локальних мінімумів є важливим аспектом в машинному навчанні, оскільки вони можуть призводити до перенавчання. Для цього існують різні методи та підходи, які дозволяють оптимізувати процес навчання та уникати застрягання у локальних мінімумах.

Логістична регресія є методом, подібним до лінійної регресії, але використовується для вирішення задач класифікації, де простір відповідей може бути набором класів. Вона дозволяє прогнозувати ймовірність належності прикладу до певного класу. Логістична регресія проектує вхідні точки на логістичну криву, яка максимально гладко переходить від 0 до 1 і використовується для класифікації.

Процес навчання логістичної регресії полягає в пошуку набору коефіцієнтів, які максимізують правильну класифікацію прикладів. Це може виконуватись за допомогою методу мінімізації емпіричного ризику, такого як градієнтний спуск. Отримані результати логістичної регресії можна інтерпретувати як відстані до межі класів.

У випадку бінарної логістичної регресії, відповіді представляються у форматі 1 або 0, вказуючи, до якого класу належить приклад. У разі софт-макс регресії, яка є розширенням логістичної регресії, можна використовувати більшу кількість класів. Відповіді у софт-макс регресії представлені розподілом ймовірностей по кожному класу.

Логістична регресія та софт-макс регресія широко використовуються в задачах класифікації, зокрема в нейронних мережах і мультикласифікації.
### День 4
#### Дані в машинному навчанні.
Все, що робить нейронна мережа - ітерація за ітерацією деформує вхідний
простір прикладів таким чином, щоб внаслідок деформації точки, які ми дали
на вході, потрапили в зони, де ми очікуємо їх побачити не виході.
Кожен із параметрів нейронної мережі відповідає за певний вид деформації
простору. Це може бути лінійна деформація, стискання, розтискання, більш
складні деформації.
Будь-яка тренувальна вибірка – це набір точок, які знаходяться в певному
просторі, незалежно від того, чи це картинки, чи це відео, чи це набір
результатів соціологічного дослідження, чи характеристики веб-сторінки, яку
ми аналізуємо. Є набір ознак, кожна ознака задає певний вимір і, відповідно,
наші дані – це величезна кількість точок в багатовимірному просторі.
Методи, якими можна деформувати простір прикладів так, щоб, вкинувши
нові точки із тестувальної вибірки, простір деформувався задля отримання
вірних результатів, в сукупності і є машинним навчанням.
Яким чином ми будемо деформувати простір, залежить від того, яка
архітектура системи.
Одним із найпоширеніших методів машинного навчання є нейронні мережі
(НМ)

Штучні НМ – це модель роботи нейронів на базі того, що було відомо в
середині ХХ століття: модель синаптичної пластичності і того, що дозволяє
біологічним нейронам адаптуватися та навчатися.

Функція активації – це спосіб трансформації нашого імпульсу в іншу
форму. Наприклад, якщо нам потрібно зробити, щоб нейрон завжди
активувався в межах від 0 до 1 незалежно від сили імпульсу від попередніх
нейронів, ми застосовуємо сигмоїдальну функцію активації (Ви про неї чули
у розділі логістичної регресії).


Нейронна мережа – це певна функція, яка має величезний
набір параметрів, які ми даємо на вхід (т.зв. вектор ознак). Ця функція
перемножує велику кількість разів параметри на певні навчені коефіцієнти
таким чином, що на виході ми отримуємо і аналізуємо інший вектор
необхідної розмірності.
В нейронних мережах завжди на вхід подається певний вектор і на виході
теж отримується вектор. 

#### Процес навчання нейронної мережі методом зворотного поширення помилки. Оцінка помилки.
В процесі навчання НМ одним із найпоширеніших методів навчання є метод
зворотного поширення помилки.
Це метод проходження по нейронній мережі, тільки в зворотному напрямку.
І, комбінуючи проходження по НМ вперед і назад, нейронні мережі вчаться.

Припустимо, у нас є набір прикладів, де у нас є вхідний і вихідний вектори.
Припустимо, на виході маємо 2 нейрони, а на вході 10. Кожен із них має
певний рівень активації.
Ми беремо вхідний приклад, активуємо кожен із вхідних нейронів,
отримуємо рівень активації входу. Далі, знаючи, які нейрони вхідного шару з
якими нейронами першого рівня прихованого шару з’єднані, ми множимо на
відповідні коефіцієнти вагів кожен із елементів вхідного вектора. В
результаті отримуємо рівень активації прихованого шару. Якщо у нас там 10
нейронів – отримаємо 10 значень. Якщо НМ має глибшу структуру,
аналогічним чином вираховуємо другий прихований шар і т.д. Наприкінці
вираховуємо рівень активації вихідного шару і отримуємо в результаті певні
значення.
Ці значення, як правило, не будуть відповідати нашим очікуванням і будуть
мати певну величину помилки. Що ми робимо в такому випадку?
По кожному із елементів, маючи приклад правильної класифікації (нашого
очікування) і поточної класифікації роботи нашої НМ, ми віднімаємо від
кожного із елементів його еталонне значення і отримуємо величину
помилки

#### Зворотне поширення помилки. Адаптивна зміна величини кроку.
Метод зворотного поширення помилки – спосіб
корегування вагів в НМ таким чином, щоб внаслідок корегування наша НМ
видавала меншу помилку на даному прикладі. Ітерація за ітерацією, надаючи
нейронній мережі приклад за прикладом і корегуючи відповідним чином ваги
в НМ пропорційно до величини помилки, ми наближаємо вектор зв’язків в
НМ до такого вигляду, в якому НМ буде видавати максимально
репрезентативні дані, які відповідатимуть нашим очікуванням.

#### Нейронні мережі зі згорткою (конволютивні)
Нейромережі зі згорткою вирішують відразу 2 задачі:
1. Вивчення нелокальних закономірностей – тобто здатність знаходити
певні закономірності, певні патерни не тільки з прив’язкою до їхнього
локального значення, а, якщо це випадок із картинкою, по всій площі
картинки.
2. Неймовірне зменшення кількості параметрів, які ми вивчаємо.


#### Max-пулінг
Макс-пулінг є методом обробки даних у конволютивних нейронних мережах, який використовується для зменшення розмірності зображень або активаційних карт попередніх шарів. В процесі макс-пулінгу розділяється вхідне зображення на неперекриваючіся віконечка (наприклад, 2x2), і для кожного віконечка обирається максимальне значення активації.

У випадку зображення, це означає, що лише найбільше значення в кожному віконечку передається на наступний шар мережі, а інші значення відкидаються. Це зменшує розмірність зображення, оскільки кожне 2x2 віконечко замінюється одним пікселем, в якому зберігається максимальне значення. Таким чином, розмір зображення зменшується у 2 рази у кожному розмірному напрямку.

Макс-пулінг допомагає сконцентрувати найважливіші ознаки зображення, зберігаючи лише найбільш активовані значення і відкидаючи менш значущі. Це також допомагає зменшити кількість параметрів, які потрібно оптимізувати в мережі, що полегшує тренування.

Макс-пулінг використовується для створення ієрархічних репрезентацій зображень у конволютивних нейронних мережах. Послідовне застосування конволюційних шарів і макс-пулінгу дозволяє виявляти все більш абстрактні ознаки зображення на різних шарах мережі, покращуючи її здатність до класифікації та розпізнавання об'єктів.

### День 5
#### Перевірка знаннь - проходження тестів.

## Тиждень 2
### День 6
#### Нейронна мережа Елмана. Приклад роботи.

Нейронна мережа Елмана є рекурентною штучною нейронною мережею, яка використовується для моделювання послідовних даних. Вона має вхідний шар, прихований шар з рекурентними зв'язками та вихідний шар. У цій мережі прихований шар зв'язаний з собою, що дозволяє зберігати інформацію про попередні стани мережі.

Мережа Елмана може використовуватися для різних завдань, таких як прогнозування часових рядів, мовний синтез, розпізнавання мови та інші. Вона здатна виявляти довготривалі залежності в послідовних даних завдяки своїм рекурентним зв'язкам.

Під час тренування мережі Елмана використовуються алгоритми, такі як зворотнє поширення помилки, які дозволяють підлаштовувати ваги мережі для досягнення бажаних вихідних результатів. Після тренування мережа може бути застосована для прогнозування майбутніх значень, аналізу даних або інших задач, пов'язаних з послідовними вхідними даними.
### День 7
#### Кластеризація та зменшення вимірності. Навчання з підкріпленням.

Кластеризація - це процес групування схожих об'єктів разом у класи або кластери, так щоб об'єкти в одному кластері були більш схожими між собою, ніж з об'єктами з інших кластерів. Кластеризація використовується для виявлення прихованих залежностей, групування схожих даних та розуміння структури даних.

Зменшення вимірності - це процес зменшення кількості вхідних змінних або вимірів у наборі даних. Його ціль полягає в тому, щоб зберегти якомога більше важливої інформації, скоротивши розмірність даних. Зменшення вимірності може полегшити обробку даних, знизити складність аналізу та забезпечити зручну візуалізацію.

Навчання з підкріпленням - це підход до машинного навчання, де агент навчається взаємодіяти з динамічним середовищем, спираючись на відмінність між правильними і неправильними діями. У навчанні з підкріпленням 
агент виконує послідовність дій в середовищі і отримує певні винагороди або покарання залежно від результатів своїх дій. Цей процес триває досягнення оптимальної стратегії агента для максимізації нагороди.

### День 8
#### LSTM-архітектура нейронних мереж.

LSTM (Long Short-Term Memory) є архітектурою рекурентних нейронних мереж, спеціально розробленою для моделювання довготривалих залежностей в послідовних даних. Вона використовується для роботи з послідовними даними різного типу, такими як мовні речення, часові ряди, звуки тощо.

У LSTM мережі використовуються спеціальні блоки пам'яті, що дозволяють мережі ефективно зберігати та використовувати інформацію з попередніх станів. Кожен блок має входи, виходи та внутрішні комірки пам'яті, які дозволяють контролювати потік інформації через мережу.

Основною перевагою LSTM є здатність моделювати довготривалі залежності, що робить їх особливо ефективними для завдань, де контекст та послідовність мають велике значення.
### День 9
#### Метод опорних векторів (Support Vector Machines)

Метод опорних векторів (Support Vector Machines, SVM) є надзвичайно популярним алгоритмом машинного навчання, використовуваним для класифікації та регресії. В основі методу лежить ідея знаходження оптимальної гіперплощини, яка розділяє два класи даних в просторі з максимально можливим зазором.

SVM шукає оптимальну гіперплощину, яка максимізує відстань між найближчими точками двох класів, відомими як опорні вектори. Цей алгоритм використовує математичний метод оптимізації для знаходження цієї оптимальної гіперплощини.

Одна з ключових переваг SVM полягає в його здатності працювати в просторах високої розмірності та знаходити нелінійні границі розділення за допомогою використання ядерної функції. Це дозволяє SVM ефективно працювати з даними, які не можуть бути лінійно розділені у вхідному просторі.
### День 10
#### Аналіз [нейронної мережі](https://www.kaggle.com/code/avk256/cats-vs-dog-dense-classification) по шару Dense
Проходження тесту, аналізування та запуск нейронної мережі.

## Висновок
Машинне навчання є ключовою технологією для отримання цінних знань з великого обсягу даних. Курс машинного навчання надав мені необхідні навички та знання для використання сучасних методів та алгоритмів машинного навчання. Я вивчив різні типи навчання, такі як навчання з вчителем, без вчителя та навчання з підкріпленням. Крім того, я отримав практичний досвід у реалізації нейромережі для розпізнавання образів. Цей курс став цінним ресурсом для мого подальшого розвитку в області машинного навчання.
Ось найважливіші теми на мою думку, які буди пройдені:
1) Машинне навчання. Типи навчання. Індуктивне та дедуктивне
навчання. - Це дало основні поняття про машинне навчання, старт;
2) Етапи розробки моделі машинного навчання;
3) Перенавчання. Тренувальна та тестувальна вибірки на прикладі нейронної мережі;
4) Мінімізація помилки. Приклад нейронних мереж. Зміна сили
зв’язків;
5) Процес навчання нейронної мережі методом зворотного
поширення помилки;
6) Зворотне поширення помилки. Зміна величини кроку.
7) Зворотне поширення помилки. Адаптивна зміна величини кроку.
8) Сучаснi бiблiотеки машинного навчання» Сучасні бібліотеки машинного навчання. NumPy. Scikitlearn. Pandas. TensorFlow, Keras;
9) Кластеризація та зменшення вимірності. Навчання з підкріплення
